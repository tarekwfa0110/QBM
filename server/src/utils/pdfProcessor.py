import sys
import json
import re
import os
import logging
import fitz
import pytesseract
from pdf2image import convert_from_path
from typing import List, Dict, Tuple, Optional, Set
from dataclasses import dataclass
import cv2
import numpy as np
from PIL import Image

@dataclass
class Question:
    number: int
    text: str
    options: List[str]
    answer: str = ""
    pdf_source: str = ""

    def to_dict(self) -> Dict:
        return {
            "questionNumber": self.number,
            "question": self.text,
            "options": self.options,
            "answer": self.answer,
            "pdfSource": self.pdf_source
        }

    def is_valid(self) -> bool:
        return (
            self.text.strip() != "" and
            len(self.options) == 4 and
            all(opt.strip() != "" for opt in self.options)
        )

class TextCleaner:
    """Handles text cleaning and OCR artifact removal"""
    
    def __init__(self):
        self.common_ocr_mistakes = {
            '1': ['l', 'I'],
            '0': ['O', 'o'],
            '5': ['S', 's'],
            '2': ['Z', 'z'],
            '8': ['B'],
            '6': ['G'],
            '9': ['g', 'q'],
        }
        
        # Build reverse mapping
        self.reverse_ocr_mistakes = {}
        for num, letters in self.common_ocr_mistakes.items():
            for letter in letters:
                self.reverse_ocr_mistakes[letter] = num
        
        self.noise_patterns = [
            r'Scanned with.*CamScanner',
            r'\(\s*\d*\s*[J]?\s*Cam\s*Scanner\s*\)',
            r'Page.*:.*',
            r'---\s*PAGE\s*\d+\s*---',
            r'\|Page.*',
            r'\\|Page.*',
            r'^\s*\d+\s*$',
            r'^\s*[A-Z]\s*$',
            r'.*www\..*\.com.*',
            r'.*http.*',
            r'.*Generated by.*',
            r'.*Powered by.*'
        ]
        
        # Common word fixes
        self.word_fixes = {
            'Whatis': 'What is',
            'itis': 'it is',
            'thisis': 'this is',
            'andthe': 'and the',
            'inthe': 'in the',
            'forthe': 'for the',
            'tothe': 'to the',
            'ofthe': 'of the',
            'isthe': 'is the',
            'onthe': 'on the',
            'bythe': 'by the',
            'withthe': 'with the',
            'fromthe': 'from the'
        }

    def fix_numbers_in_text(self, text: str) -> str:
        """Fix common OCR number mistakes in text"""
        if not text:
            return text
            
        words = text.split()
        fixed_words = []
        
        for word in words:
            if len(word) <= 2:
                fixed_words.append(word)
                continue
                
            if all(c.isdigit() or c in self.reverse_ocr_mistakes for c in word):
                fixed_word = ''
                for c in word:
                    if c in self.reverse_ocr_mistakes:
                        fixed_word += self.reverse_ocr_mistakes[c]
                    else:
                        fixed_word += c
                fixed_words.append(fixed_word)
            else:
                fixed_words.append(word)
        
        return ' '.join(fixed_words)

    def fix_common_words(self, text: str) -> str:
        """Fix common word joining issues"""
        for wrong, right in self.word_fixes.items():
            text = re.sub(r'\b' + wrong + r'\b', right, text, flags=re.IGNORECASE)
        return text

    def remove_noise(self, text: str) -> str:
        """Remove common noise patterns from text"""
        for pattern in self.noise_patterns:
            text = re.sub(pattern, '', text, flags=re.IGNORECASE)
        return text.strip()

    def clean_text(self, text: str) -> str:
        """Complete text cleaning pipeline"""
        if not text:
            return text
            
        text = text.replace('\u2018', "'").replace('\u2019', "'")
        text = text.replace('\u201c', '"').replace('\u201d', '"')
        text = text.replace('\xa0', ' ')
        
        text = self.fix_numbers_in_text(text)
        text = self.fix_common_words(text)
        text = self.remove_noise(text)
        
        return ' '.join(text.split()).strip()

class OCRPreprocessor:
    """Handles image preprocessing for better OCR results"""
    
    @staticmethod
    def preprocess_image(image: Image.Image) -> Image.Image:
        cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
        binary = cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
            cv2.THRESH_BINARY, 11, 2
        )
        denoised = cv2.fastNlMeansDenoising(binary)
        return Image.fromarray(denoised)

class PDFQuestionExtractor:
    def __init__(self, poppler_path: str, tesseract_path: str):
        self.logger = self._setup_logging()
        self.poppler_path = poppler_path
        pytesseract.pytesseract.tesseract_cmd = tesseract_path
        self.text_cleaner = TextCleaner()
        self.ocr_preprocessor = OCRPreprocessor()
        
        self.question_patterns = [
            r'^\s*(\d+)[\.\)]\s*(.*)',
            r'^\s*Q\.?\s*(\d+)[\.\)]\s*(.*)',
            r'^\s*Question\s*(\d+)[\.\)]\s*(.*)',
            r'^\s*(\d+)\s*[\.\)]\s*What\s+is\s*(.*)',
            r'^\s*(\d+)\s*[\.\)]\s*Which\s+(.*)'
        ]
        
        self.option_patterns = [
            r'^\s*([a-d])[\.\)]\s*(.*)',
            r'^\s*\(([a-d])\)\s*(.*)',
            r'^\s*Option\s*([a-d])[\.\)]\s*(.*)'
        ]
        
        self.answer_section_patterns = [
            r'^\s*Answers?\s*$',
            r'^\s*Answer\s+Key\s*$',
            r'^\s*Solutions?\s*$',
            r'^\s*Correct\s+Answers?\s*$'
        ]

    def _setup_logging(self) -> logging.Logger:
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        return logging.getLogger(__name__)

    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """Extract text from PDF using both PDF text extraction and OCR"""
        try:
            # Try normal PDF text extraction first
            doc = fitz.open(pdf_path)
            text = ""
            for page in doc:
                text += page.get_text("text", sort=True) + "\n"
            
            # If no text found, use OCR
            if not text.strip():
                self.logger.info("No text found in PDF, trying OCR...")
                images = convert_from_path(pdf_path, poppler_path=self.poppler_path)
                text = ""
                for img in images:
                    text += pytesseract.image_to_string(img) + "\n"
            
            # Save extracted text for debugging
            debug_path = f"{os.path.splitext(pdf_path)[0]}_extracted.txt"
            with open(debug_path, "w", encoding="utf-8") as f:
                f.write(text)
            
            return text
            
        except Exception as e:
            self.logger.error(f"Error extracting text: {e}")
            raise

    def extract_questions(self, text: str, pdf_path: str) -> List[Question]:
        """Extract questions and options from the text"""
        try:
            lines = text.split('\n')
            cleaned_lines = []
            
            for line in lines:
                clean_line = self.text_cleaner.clean_text(line)
                if clean_line:
                    cleaned_lines.append(clean_line)
            
            answer_section_start = -1
            for i, line in enumerate(cleaned_lines):
                if any(re.search(pattern, line, re.IGNORECASE) for pattern in self.answer_section_patterns):
                    answer_section_start = i
                    self.logger.info(f"Found answers section at line {i}: '{line}'")
                    break
            
            questions = []
            current_question = None
            questions_dict = {}
            i = 0
            
            while i < len(cleaned_lines) and (answer_section_start == -1 or i < answer_section_start):
                line = cleaned_lines[i]
                
                question_match = None
                for pattern in self.question_patterns:
                    match = re.match(pattern, line, re.IGNORECASE)
                    if match:
                        question_match = match
                        break
                
                if question_match:
                    if current_question and current_question.is_valid():
                        if current_question.number not in questions_dict or (
                            len(current_question.text) > len(questions_dict[current_question.number].text)
                        ):
                            questions_dict[current_question.number] = current_question
                    
                    question_num = int(question_match.group(1))
                    question_text = self.text_cleaner.clean_text(question_match.group(2))
                    
                    current_question = Question(
                        number=question_num,
                        text=question_text,
                        options=[],
                        pdf_source=os.path.basename(pdf_path)
                    )
                    
                    i += 1
                    while i < len(cleaned_lines) and i < answer_section_start:
                        next_line = cleaned_lines[i]
                        if any(re.match(p, next_line, re.IGNORECASE) for p in self.option_patterns + self.question_patterns):
                            break
                        current_question.text += ' ' + self.text_cleaner.clean_text(next_line)
                        i += 1
                    continue
                
                option_match = None
                for pattern in self.option_patterns:
                    match = re.match(pattern, line, re.IGNORECASE)
                    if match:
                        option_match = match
                        break
                
                if option_match and current_question and len(current_question.options) < 4:
                    option_text = self.text_cleaner.clean_text(option_match.group(2))
                    if option_text:
                        current_question.options.append(option_text)
                
                i += 1
            
            if current_question and current_question.is_valid():
                if current_question.number not in questions_dict or (
                    len(current_question.text) > len(questions_dict[current_question.number].text)
                ):
                    questions_dict[current_question.number] = current_question
            
            questions = sorted(questions_dict.values(), key=lambda x: x.number)
            return questions, answer_section_start, cleaned_lines
            
        except Exception as e:
            self.logger.error(f"Error in question extraction: {str(e)}")
            raise

    def extract_answers(self, lines: List[str], start_index: int, questions: List[Question]) -> List[Question]:
        """Extract answers from the answer section"""
        if start_index == -1:
            self.logger.warning("No answers section found")
            return questions
        
        try:
            question_map = {q.number: q for q in questions}
            
            answer_patterns = [
                r'(\d+)[\s\.\)]*(?:\()?([a-d])(?:\))?',
                r'(\d+)[\s\.\)]*(?:option\s+)?([a-d])',
                r'(?:question\s+)?(\d+)[\s\.\)]*([a-d])',
                r'(\d+)[\s\.\)]*(?:answer\s+)?([a-d])',
                r'(\d+)[\s\.\)]*(?:ans\s+)?([a-d])',
                r'(\d+)[\s\.\)]*=\s*([a-d])'
            ]
            
            processed_answers = set()
            
            i = start_index + 1
            while i < len(lines):
                line = self.text_cleaner.clean_text(lines[i]).lower()
                
                for pattern in answer_patterns:
                    match = re.search(pattern, line, re.IGNORECASE)
                    if match:
                        try:
                            q_num = int(match.group(1))
                            answer = match.group(2).lower()
                            
                            if q_num in question_map and q_num not in processed_answers:
                                question_map[q_num].answer = answer
                                processed_answers.add(q_num)
                                self.logger.info(f"Found answer for question {q_num}: {answer}")
                                break
                        except (ValueError, IndexError) as e:
                            self.logger.warning(f"Error processing answer match: {str(e)}")
                i += 1
            
            return list(question_map.values())
            
        except Exception as e:
            self.logger.error(f"Error in answer extraction: {str(e)}")
            raise

    def process_pdf(self, pdf_path: str) -> List[Dict]:
        """Process a PDF file and extract questions with answers"""
        try:
            self.logger.info(f"Processing PDF: {pdf_path}")
            
            text = self.extract_text_from_pdf(pdf_path)
            questions, answer_section_start, cleaned_lines = self.extract_questions(text, pdf_path)
            
            if not questions:
                self.logger.warning("No questions found in the PDF")
                return []
            
            self.logger.info(f"Found {len(questions)} questions")
            questions = self.extract_answers(cleaned_lines, answer_section_start, questions)
            
            # Convert questions to dictionary format
            return [q.to_dict() for q in questions if q.is_valid()]
            
        except Exception as e:
            self.logger.error(f"Error processing PDF {pdf_path}: {str(e)}")
            raise

def main():
    """Main entry point for the script"""
    try:
        if len(sys.argv) != 2:
            print(json.dumps({"error": "PDF path required"}))
            sys.exit(1)
        
        pdf_path = sys.argv[1]
        if not os.path.exists(pdf_path):
            print(json.dumps({"error": f"PDF file not found: {pdf_path}"}))
            sys.exit(1)
            
        extractor = PDFQuestionExtractor(POPPLER_PATH, TESSERACT_PATH)
        questions = extractor.process_pdf(pdf_path)
        
        # Prepare output
        output = {
            "filename": os.path.basename(pdf_path),
            "total_questions": len(questions),
            "questions": questions
        }
        
        # Save results to JSON file
        output_path = f"{os.path.splitext(pdf_path)[0]}_questions.json"
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output, f, indent=2, ensure_ascii=False)
            
        print(json.dumps(output, indent=2))
        
    except Exception as e:
        print(json.dumps({"error": str(e)}))
        sys.exit(1)

if __name__ == "__main__":
    main()